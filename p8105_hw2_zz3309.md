P8105_hw2_zz3309
================
Zebang Zhang
2024-09-27

Show libraries used.

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readxl)
```

## Problem 1

Import data, change column types, clean variable names, select variables
wanted, and convert the entry variable from character to a logical
variable.

``` r
nyc_transit = 
  read_csv(
    "./hw2_datasets/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) |> 
  janitor::clean_names() |> 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) |> 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

``` r
names(nyc_transit)
```

    ##  [1] "line"              "station_name"      "station_latitude" 
    ##  [4] "station_longitude" "route1"            "route2"           
    ##  [7] "route3"            "route4"            "route5"           
    ## [10] "route6"            "route7"            "route8"           
    ## [13] "route9"            "route10"           "route11"          
    ## [16] "entry"             "exit_only"         "vending"          
    ## [19] "entrance_type"     "ada"

``` r
cat("This dataset has", nrow(nyc_transit), "rows and", ncol(nyc_transit), 'columns.')
```

    ## This dataset has 1868 rows and 20 columns.

These data are not tidy, route number and route name should both be
variables.

``` r
#calculate distinct stations
stations=
  nyc_transit |> 
  select(station_name, line) |> 
  distinct()
stations
```

    ## # A tibble: 465 × 2
    ##    station_name             line    
    ##    <chr>                    <chr>   
    ##  1 25th St                  4 Avenue
    ##  2 36th St                  4 Avenue
    ##  3 45th St                  4 Avenue
    ##  4 53rd St                  4 Avenue
    ##  5 59th St                  4 Avenue
    ##  6 77th St                  4 Avenue
    ##  7 86th St                  4 Avenue
    ##  8 95th St                  4 Avenue
    ##  9 9th St                   4 Avenue
    ## 10 Atlantic Av-Barclays Ctr 4 Avenue
    ## # ℹ 455 more rows

``` r
#calculate ADA-compliant stations 
ada_compliant_stat=
  nyc_transit |> 
  filter(ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
ada_compliant_stat
```

    ## # A tibble: 84 × 2
    ##    station_name                   line           
    ##    <chr>                          <chr>          
    ##  1 Atlantic Av-Barclays Ctr       4 Avenue       
    ##  2 DeKalb Av                      4 Avenue       
    ##  3 Pacific St                     4 Avenue       
    ##  4 Grand Central                  42nd St Shuttle
    ##  5 34th St                        6 Avenue       
    ##  6 47-50th Sts Rockefeller Center 6 Avenue       
    ##  7 Church Av                      6 Avenue       
    ##  8 21st St                        63rd Street    
    ##  9 Lexington Av                   63rd Street    
    ## 10 Roosevelt Island               63rd Street    
    ## # ℹ 74 more rows

``` r
#calculate proportion of station entrances / exits without vending allow entrance
proportion= 
  nyc_transit |> 
  filter(vending == "NO") |> 
  pull(entry) |> 
  mean()
proportion
```

    ## [1] 0.3770492

``` r
#Reformat data so that route number and route name are distinct variables
nyc_transit_tidy= nyc_transit |> 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route_name")
```

``` r
nyc_transit_tidy |>
  filter(route_name== "A") |> 
  select(station_name, line) |> 
  distinct()
```

    ## # A tibble: 60 × 2
    ##    station_name                  line           
    ##    <chr>                         <chr>          
    ##  1 Times Square                  42nd St Shuttle
    ##  2 125th St                      8 Avenue       
    ##  3 145th St                      8 Avenue       
    ##  4 14th St                       8 Avenue       
    ##  5 168th St - Washington Heights 8 Avenue       
    ##  6 175th St                      8 Avenue       
    ##  7 181st St                      8 Avenue       
    ##  8 190th St                      8 Avenue       
    ##  9 34th St                       8 Avenue       
    ## 10 42nd St                       8 Avenue       
    ## # ℹ 50 more rows

``` r
nyc_transit_tidy |>
  filter(route_name == "A", ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
```

    ## # A tibble: 17 × 2
    ##    station_name                  line            
    ##    <chr>                         <chr>           
    ##  1 14th St                       8 Avenue        
    ##  2 168th St - Washington Heights 8 Avenue        
    ##  3 175th St                      8 Avenue        
    ##  4 34th St                       8 Avenue        
    ##  5 42nd St                       8 Avenue        
    ##  6 59th St                       8 Avenue        
    ##  7 Inwood - 207th St             8 Avenue        
    ##  8 West 4th St                   8 Avenue        
    ##  9 World Trade Center            8 Avenue        
    ## 10 Times Square-42nd St          Broadway        
    ## 11 59th St-Columbus Circle       Broadway-7th Ave
    ## 12 Times Square                  Broadway-7th Ave
    ## 13 8th Av                        Canarsie        
    ## 14 Franklin Av                   Franklin        
    ## 15 Euclid Av                     Fulton          
    ## 16 Franklin Av                   Fulton          
    ## 17 Howard Beach                  Rockaway

## Problem 2

First, I read and clean the Mr. Trash Wheel sheet.

I use the arguement “range” in read_excel() to omit non-data entries; I
use clean_names() in janitor to have reasonable variable names; I omit
rows that do not include dumpster-specific data by removing the rows
whose ‘dumpster’ are NA and by removing the rows that only contain valid
value of ‘dumpster’.

``` r
mr_trash_df = 
  read_excel("./hw2_datasets/202409 Trash Wheel Collection Data.xlsx",
               sheet = "Mr. Trash Wheel",
               range = "A2:N655",
               na = c(".", "NA", "")) |>
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |>
  filter(!if_all(-dumpster, is.na)) |>
  mutate(sports_balls = as.integer(round(sports_balls)))

print(mr_trash_df)
```

    ## # A tibble: 651 × 14
    ##    dumpster month year  date                weight_tons volume_cubic_yards
    ##       <dbl> <chr> <chr> <dttm>                    <dbl>              <dbl>
    ##  1        1 May   2014  2014-05-16 00:00:00        4.31                 18
    ##  2        2 May   2014  2014-05-16 00:00:00        2.74                 13
    ##  3        3 May   2014  2014-05-16 00:00:00        3.45                 15
    ##  4        4 May   2014  2014-05-17 00:00:00        3.1                  15
    ##  5        5 May   2014  2014-05-17 00:00:00        4.06                 18
    ##  6        6 May   2014  2014-05-20 00:00:00        2.71                 13
    ##  7        7 May   2014  2014-05-21 00:00:00        1.91                  8
    ##  8        8 May   2014  2014-05-28 00:00:00        3.7                  16
    ##  9        9 June  2014  2014-06-05 00:00:00        2.52                 14
    ## 10       10 June  2014  2014-06-11 00:00:00        3.76                 18
    ## # ℹ 641 more rows
    ## # ℹ 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <int>, homes_powered <dbl>

Then I use a similar process to import, clean, and organize the data for
Professor Trash Wheel.

``` r
prof_trash_df = 
  read_excel("./hw2_datasets/202409 Trash Wheel Collection Data.xlsx",
               sheet = "Professor Trash Wheel",
               range = "A2:M123",
               na = c(".", "NA", "")) |>
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |>
  filter(!if_all(-dumpster, is.na)) 

print(prof_trash_df)
```

    ## # A tibble: 118 × 13
    ##    dumpster month     year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>    <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 January   2017 2017-01-02 00:00:00        1.79                 15
    ##  2        2 January   2017 2017-01-30 00:00:00        1.58                 15
    ##  3        3 February  2017 2017-02-26 00:00:00        2.32                 18
    ##  4        4 February  2017 2017-02-26 00:00:00        3.72                 15
    ##  5        5 February  2017 2017-02-28 00:00:00        1.45                 15
    ##  6        6 March     2017 2017-03-30 00:00:00        1.71                 15
    ##  7        7 April     2017 2017-04-01 00:00:00        1.82                 15
    ##  8        8 April     2017 2017-04-20 00:00:00        2.37                 15
    ##  9        9 May       2017 2017-05-10 00:00:00        2.64                 15
    ## 10       10 May       2017 2017-05-26 00:00:00        2.78                 15
    ## # ℹ 108 more rows
    ## # ℹ 7 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, homes_powered <dbl>

Then I use a similar process to import, clean, and organize the data for
Gwynnda Trash Wheel.

``` r
gwy_trash_df = 
  read_excel("./hw2_datasets/202409 Trash Wheel Collection Data.xlsx",
               sheet = "Gwynnda Trash Wheel",
               range = "A2:L266",
               na = c(".", "NA", "")) |>
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |>
  filter(!if_all(-dumpster, is.na)) 

print(gwy_trash_df)
```

    ## # A tibble: 263 × 12
    ##    dumpster month   year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>  <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 July    2021 2021-07-03 00:00:00        0.93                 15
    ##  2        2 July    2021 2021-07-07 00:00:00        2.26                 15
    ##  3        3 July    2021 2021-07-07 00:00:00        1.62                 15
    ##  4        4 July    2021 2021-07-16 00:00:00        1.76                 15
    ##  5        5 July    2021 2021-07-30 00:00:00        1.53                 15
    ##  6        6 August  2021 2021-08-11 00:00:00        2.06                 15
    ##  7        7 August  2021 2021-08-14 00:00:00        1.9                  15
    ##  8        8 August  2021 2021-08-16 00:00:00        2.16                 15
    ##  9        9 August  2021 2021-08-16 00:00:00        2.6                  15
    ## 10       10 August  2021 2021-08-17 00:00:00        3.21                 15
    ## # ℹ 253 more rows
    ## # ℹ 6 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, plastic_bags <dbl>, wrappers <dbl>,
    ## #   homes_powered <dbl>

After that, time to combine datasets.  
I firstly add a variable called ‘type’ for each of the three data frames
so that I can keep track of which trash wheel is which (and let it be
the first column). Then I deleted column ‘dumpster’ in each dataframe
because ‘dumpster’ values are confusing and not important. Then adjust
the column type of all ‘year’ columns to be the same. Lastly, the three
datasets can be combined to be a single tidy one.

``` r
mr_trash_df <- mr_trash_df |>
  mutate(type = "mr") |>
  relocate(type) |>
  select(-dumpster) |>
  mutate(year = as.character(year))

prof_trash_df <- prof_trash_df |>
  mutate(type = "prof") |>
  relocate(type) |>
  select(-dumpster) |>
  mutate(year = as.character(year))

gwy_trash_df <- gwy_trash_df |>
  mutate(type = "gwy") |>
  relocate(type) |>
  select(-dumpster) |>
  mutate(year = as.character(year))

merged_df = 
  bind_rows(mr_trash_df, prof_trash_df, gwy_trash_df)
print(merged_df)
```

    ## # A tibble: 1,032 × 14
    ##    type  month year  date                weight_tons volume_cubic_yards
    ##    <chr> <chr> <chr> <dttm>                    <dbl>              <dbl>
    ##  1 mr    May   2014  2014-05-16 00:00:00        4.31                 18
    ##  2 mr    May   2014  2014-05-16 00:00:00        2.74                 13
    ##  3 mr    May   2014  2014-05-16 00:00:00        3.45                 15
    ##  4 mr    May   2014  2014-05-17 00:00:00        3.1                  15
    ##  5 mr    May   2014  2014-05-17 00:00:00        4.06                 18
    ##  6 mr    May   2014  2014-05-20 00:00:00        2.71                 13
    ##  7 mr    May   2014  2014-05-21 00:00:00        1.91                  8
    ##  8 mr    May   2014  2014-05-28 00:00:00        3.7                  16
    ##  9 mr    June  2014  2014-06-05 00:00:00        2.52                 14
    ## 10 mr    June  2014  2014-06-11 00:00:00        3.76                 18
    ## # ℹ 1,022 more rows
    ## # ℹ 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <int>, homes_powered <dbl>

``` r
names(merged_df)
```

    ##  [1] "type"               "month"              "year"              
    ##  [4] "date"               "weight_tons"        "volume_cubic_yards"
    ##  [7] "plastic_bottles"    "polystyrene"        "cigarette_butts"   
    ## [10] "glass_bottles"      "plastic_bags"       "wrappers"          
    ## [13] "sports_balls"       "homes_powered"

``` r
n_rows <- nrow(merged_df)
cat("The number of observations in the resulting dataset is", n_rows, "\n")
```

    ## The number of observations in the resulting dataset is 1032

``` r
# In the resulting dataset, 'weight_tons', 'volume_cubic_yards', 'plastic_bottles' are some key variables so I randomly select three samples of 10 to give examples of their values.

set.seed(123)
sampled_weights <- merged_df |>
  filter(!is.na(weight_tons)) |>
  pull(weight_tons) |>
  sample(10)
cat("Example values of weight_tons:", sampled_weights, "\n")
```

    ## Example values of weight_tons: 3.44 2.55 3.13 2.83 2.59 2.79 1.69 2.15 3.08 3

``` r
sampled_volume <- merged_df |>
  filter(!is.na(volume_cubic_yards)) |>
  pull(volume_cubic_yards) |>
  sample(10)
cat("Example values of volume_cubic_yards:", sampled_volume, "\n")
```

    ## Example values of volume_cubic_yards: 15 15 15 15 15 15 17 15 15 15

``` r
sampled_plastic_bottles <- merged_df |>
  filter(!is.na(plastic_bottles)) |>
  pull(plastic_bottles) |>
  sample(10)
cat("Example values of plastic_bottles:", sampled_plastic_bottles, "\n")
```

    ## Example values of plastic_bottles: 2980 540 750 750 1000 1200 1800 1800 2100 2700

Then calculate the total weight of trash collected by Professor Trash
Wheel and the total number of cigarette butts collected by Gwynnda in
June of 2022.

``` r
total_weight_prof <- merged_df |>
  filter(type == "prof") |>
  summarize(total_weight = sum(weight_tons)) |>
  pull(total_weight)

cat("The total weight (tons) of trash collected by Professor Trash Wheel is", total_weight_prof, "\n")
```

    ## The total weight (tons) of trash collected by Professor Trash Wheel is 246.74

``` r
total_cigarette_gwy_7_2022 <- merged_df |>
  filter(type == "gwy", month == 'July', year == '2022') |>
  summarize(total_cigarette = sum(cigarette_butts)) |>
  pull(total_cigarette)

cat("The total number of cigarette butts collected by Gwynnda in June of 2022 is", total_cigarette_gwy_7_2022, "\n")
```

    ## The total number of cigarette butts collected by Gwynnda in June of 2022 is 31090

For available data, the total weight of trash collected by Professor
Trash Wheel is 246.74 tons, the total number of cigarette butts
collected by Gwynnda in June of 2022 is 3.109^{4}.

## Problem 3

First, import the three datasets: bakers.csv, bakes.csv, and results.csv
.

``` r
bakes_df = 
  read_csv("./hw2_datasets/gbb_datasets/bakes.csv", na = c("UNKNOWN", "N/A", "")) |>
  janitor::clean_names()
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
print(bakes_df)
```

    ## # A tibble: 548 × 5
    ##    series episode baker     signature_bake                          show_stopper
    ##     <dbl>   <dbl> <chr>     <chr>                                   <chr>       
    ##  1      1       1 Annetha   "Light Jamaican Black Cakewith Strawbe… Red, White …
    ##  2      1       1 David     "Chocolate Orange Cake"                 Black Fores…
    ##  3      1       1 Edd       "Caramel Cinnamon and Banana Cake"      <NA>        
    ##  4      1       1 Jasminder "Fresh Mango and Passion Fruit Humming… <NA>        
    ##  5      1       1 Jonathan  "Carrot Cake with Lime and Cream Chees… Three Tiere…
    ##  6      1       1 Lea       "Cranberry and Pistachio Cakewith Oran… Raspberries…
    ##  7      1       1 Louise    "Carrot and Orange Cake"                Never Fail …
    ##  8      1       1 Mark      "Sticky Marmalade Tea Loaf"             Heart-shape…
    ##  9      1       1 Miranda   "Triple Layered Brownie Meringue Cake\… Three Tiere…
    ## 10      1       1 Ruth      "Three Tiered Lemon Drizzle Cakewith F… Classic Cho…
    ## # ℹ 538 more rows

``` r
bakers_df = 
  read_csv("./hw2_datasets/gbb_datasets/bakers.csv", na = c("NA", "N/A", "")) |>
  janitor::clean_names()
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
print(bakers_df)
```

    ## # A tibble: 120 × 5
    ##    baker_name       series baker_age baker_occupation             hometown      
    ##    <chr>             <dbl>     <dbl> <chr>                        <chr>         
    ##  1 Ali Imdad             4        25 Charity worker               Saltley, Birm…
    ##  2 Alice Fevronia       10        28 Geography teacher            Essex         
    ##  3 Alvin Magallanes      6        37 Nurse                        Bracknell, Be…
    ##  4 Amelia LeBruin       10        24 Fashion designer             Halifax       
    ##  5 Andrew Smyth          7        25 Aerospace engineer           Derby / Holyw…
    ##  6 Annetha Mills         1        30 Midwife                      Essex         
    ##  7 Antony Amourdoux      9        30 Banker                       London        
    ##  8 Beca Lyne-Pirkis      4        31 Military Wives' Choir Singer Aldershot, Ha…
    ##  9 Ben Frazer            2        31 Graphic Designer             Northampton   
    ## 10 Benjamina Ebuehi      7        23 Teaching assistant           South London  
    ## # ℹ 110 more rows

``` r
results_df = 
  read_csv("./hw2_datasets/gbb_datasets/results.csv",na = c("NA", ""),
           skip = 2) |>
  janitor::clean_names()
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
print(results_df)
```

    ## # A tibble: 1,136 × 5
    ##    series episode baker     technical result
    ##     <dbl>   <dbl> <chr>         <dbl> <chr> 
    ##  1      1       1 Annetha           2 IN    
    ##  2      1       1 David             3 IN    
    ##  3      1       1 Edd               1 IN    
    ##  4      1       1 Jasminder        NA IN    
    ##  5      1       1 Jonathan          9 IN    
    ##  6      1       1 Louise           NA IN    
    ##  7      1       1 Miranda           8 IN    
    ##  8      1       1 Ruth             NA IN    
    ##  9      1       1 Lea              10 OUT   
    ## 10      1       1 Mark             NA OUT   
    ## # ℹ 1,126 more rows

Aftering importing and viewing each datasets, then we had better check
for completeness and correctness across datasets by using anti_join().

``` r
anti_join(bakers_df,bakes_df, by=c('series'))
```

    ## # A tibble: 25 × 5
    ##    baker_name          series baker_age baker_occupation               hometown 
    ##    <chr>                <dbl>     <dbl> <chr>                          <chr>    
    ##  1 Alice Fevronia          10        28 Geography teacher              Essex    
    ##  2 Amelia LeBruin          10        24 Fashion designer               Halifax  
    ##  3 Antony Amourdoux         9        30 Banker                         London   
    ##  4 Briony Williams          9        33 Full-time parent               Bristol  
    ##  5 Dan Beasley-Harling      9        36 Full-time parent               London   
    ##  6 Dan Chambers            10        32 Support worker                 Rotherham
    ##  7 David Atherton          10        36 International health adviser   Whitby   
    ##  8 Helena Garcia           10        40 Online project manager         Leeds    
    ##  9 Henry Bird              10        20 Student                        Durham   
    ## 10 Imelda McCarron          9        33 Countryside recreation officer County T…
    ## # ℹ 15 more rows

``` r
anti_join(bakes_df,bakers_df, by=c('series'))
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: series <dbl>, episode <dbl>, baker <chr>,
    ## #   signature_bake <chr>, show_stopper <chr>

``` r
anti_join(results_df,bakes_df, by=c('series','baker','episode'))
```

    ## # A tibble: 596 × 5
    ##    series episode baker    technical result
    ##     <dbl>   <dbl> <chr>        <dbl> <chr> 
    ##  1      1       2 Lea             NA <NA>  
    ##  2      1       2 Mark            NA <NA>  
    ##  3      1       3 Annetha         NA <NA>  
    ##  4      1       3 Lea             NA <NA>  
    ##  5      1       3 Louise          NA <NA>  
    ##  6      1       3 Mark            NA <NA>  
    ##  7      1       4 Annetha         NA <NA>  
    ##  8      1       4 Jonathan        NA <NA>  
    ##  9      1       4 Lea             NA <NA>  
    ## 10      1       4 Louise          NA <NA>  
    ## # ℹ 586 more rows

``` r
anti_join(bakes_df,results_df, by=c('series','baker','episode'))
```

    ## # A tibble: 8 × 5
    ##   series episode baker    signature_bake                            show_stopper
    ##    <dbl>   <dbl> <chr>    <chr>                                     <chr>       
    ## 1      2       1 "\"Jo\"" Chocolate Orange CupcakesOrange and Card… Chocolate a…
    ## 2      2       2 "\"Jo\"" Caramelised Onion, Gruyere and Thyme Qui… Raspberry a…
    ## 3      2       3 "\"Jo\"" Stromboli flavored with Mozzarella, Ham,… Unknown     
    ## 4      2       4 "\"Jo\"" Lavender Biscuits                         Blueberry M…
    ## 5      2       5 "\"Jo\"" Salmon and Asparagus Pie                  Apple and R…
    ## 6      2       6 "\"Jo\"" Rum and Raisin Baked Cheesecake           Limoncello …
    ## 7      2       7 "\"Jo\"" Raspberry & Strawberry Mousse Cake        Pain Aux Ra…
    ## 8      2       8 "\"Jo\"" Raspberry and Blueberry Mille Feuille     Mini Victor…

``` r
anti_join(results_df,bakers_df, by=c('series'))
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: series <dbl>, episode <dbl>, baker <chr>, technical <dbl>,
    ## #   result <chr>

``` r
anti_join(bakers_df, results_df, by=c('series'))
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: baker_name <chr>, series <dbl>, baker_age <dbl>,
    ## #   baker_occupation <chr>, hometown <chr>

Using anti_join() between bakers_df and bakes_df, I discovered that it
seems like bakes_df lacks data of series 9 and 10.  
However, then when using anti_join() between results_df and bakes_df, I
discovered that a person called ‘Jo’ appears in bakes_df but doesn’t
appear in results_df, this is kind of weird because a ‘Joanne’ in
results_df but not in bakes_df. ‘Jo’ and ‘Joanne’ data are the same in
‘series’ and ‘episode’. Other data that results_df has but bakes_df does
not have is data of series 9 and 10, as well as the NA data in series
1-8.  
From these signs, I infer that the ‘Jo’ in bakes_df is actually the
‘Joanne’ in results_df, so in the next step, I will mutate the ‘Jo’ in
bakes_df to ‘Joanne’.  
I will add another column called ‘baker’ (derived from ‘baker_name’) for
bakers_df in order to merge the three datasets in the future.

``` r
bakes_df <- bakes_df |>
  mutate(baker = ifelse(baker == '"Jo"' , 'Joanne', baker))

bakers_df <- bakers_df |>
  mutate(baker = sapply(strsplit(baker_name, " "), `[`, 1)) |>
  relocate('baker','series')
```

Then, it’s time to merge datasets, because results_df is the most
complete dataset and has the largest number of rows (although exist some
NA values), I choose to join the other two datasets to results_df one by
one by using left_join(). At last, I rearrange the order of columns to
become more reasonable.

``` r
combined_df=
  left_join(results_df, bakes_df, by=c('baker','series','episode')) |>
  relocate('baker','series','episode')

combined_df=
  left_join(combined_df, bakers_df, by=c('baker','series')) |>
  select(baker,series, episode, technical, signature_bake, show_stopper, result, everything())

print(combined_df)
```

    ## # A tibble: 1,136 × 11
    ##    baker  series episode technical signature_bake show_stopper result baker_name
    ##    <chr>   <dbl>   <dbl>     <dbl> <chr>          <chr>        <chr>  <chr>     
    ##  1 Annet…      1       1         2 "Light Jamaic… Red, White … IN     Annetha M…
    ##  2 David       1       1         3 "Chocolate Or… Black Fores… IN     David Cha…
    ##  3 Edd         1       1         1 "Caramel Cinn… <NA>         IN     Edd Kimber
    ##  4 Jasmi…      1       1        NA "Fresh Mango … <NA>         IN     Jasminder…
    ##  5 Jonat…      1       1         9 "Carrot Cake … Three Tiere… IN     Jonathan …
    ##  6 Louise      1       1        NA "Carrot and O… Never Fail … IN     Louise Br…
    ##  7 Miran…      1       1         8 "Triple Layer… Three Tiere… IN     Miranda B…
    ##  8 Ruth        1       1        NA "Three Tiered… Classic Cho… IN     Ruth Clem…
    ##  9 Lea         1       1        10 "Cranberry an… Raspberries… OUT    Lea Harris
    ## 10 Mark        1       1        NA "Sticky Marma… Heart-shape… OUT    Mark Whit…
    ## # ℹ 1,126 more rows
    ## # ℹ 3 more variables: baker_age <dbl>, baker_occupation <chr>, hometown <chr>

``` r
cat("The final dataset has ", nrow(combined_df), "rows and", ncol(combined_df), 'columns.')
```

    ## The final dataset has  1136 rows and 11 columns.

``` r
names(combined_df)
```

    ##  [1] "baker"            "series"           "episode"          "technical"       
    ##  [5] "signature_bake"   "show_stopper"     "result"           "baker_name"      
    ##  [9] "baker_age"        "baker_occupation" "hometown"

A minor drawback of the final dataset is that it contains some NA
values. In a specific series, if a contestant is out, his data in the
following episodes are NA but his name will still appear in the
following episodes in the final dataset.

``` r
#Export the final datasets as a CSV in the directory containing the original datasets
write.csv(combined_df, file = "./hw2_datasets/gbb_datasets/final_datasets_gbb.csv")
```

Create a reader-friendly table showing the star baker or winner of each
episode in Seasons 5 through 10.

``` r
filtered_df <- combined_df |>
  filter(series >= 5 & series <= 10, result %in% c("WINNER", "STAR BAKER")) |>
  select(baker_name, series, episode, result)
print(filtered_df)
```

    ## # A tibble: 60 × 4
    ##    baker_name        series episode result    
    ##    <chr>              <dbl>   <dbl> <chr>     
    ##  1 Nancy Birtwhistle      5       1 STAR BAKER
    ##  2 Richard Burr           5       2 STAR BAKER
    ##  3 Luis Troyano           5       3 STAR BAKER
    ##  4 Richard Burr           5       4 STAR BAKER
    ##  5 Kate Henry             5       5 STAR BAKER
    ##  6 Chetna Makan           5       6 STAR BAKER
    ##  7 Richard Burr           5       7 STAR BAKER
    ##  8 Richard Burr           5       8 STAR BAKER
    ##  9 Richard Burr           5       9 STAR BAKER
    ## 10 Nancy Birtwhistle      5      10 WINNER    
    ## # ℹ 50 more rows

In most seasons, the winner is often the person who has won several
times throughout the season, so maybe we can predict that the winner in
a season will be the person who have won several episodes. But in season
10, David Atherton is the winner but he hasn’t won in the previous
episodes, so this is kind of a surprise.

Import, clean, tidy, and organize the viewership data.

``` r
viewers_df = 
  read_csv("./hw2_datasets/gbb_datasets/viewers.csv",na = c("NA", "")) |>
  janitor::clean_names()
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
viewers_tidy_df = 
  pivot_longer(
    viewers_df, 
    series_1:series_10,
    names_to = "series", 
    values_to = "viewership")

head(viewers_tidy_df, 10)
```

    ## # A tibble: 10 × 3
    ##    episode series    viewership
    ##      <dbl> <chr>          <dbl>
    ##  1       1 series_1        2.24
    ##  2       1 series_2        3.1 
    ##  3       1 series_3        3.85
    ##  4       1 series_4        6.6 
    ##  5       1 series_5        8.51
    ##  6       1 series_6       11.6 
    ##  7       1 series_7       13.6 
    ##  8       1 series_8        9.46
    ##  9       1 series_9        9.55
    ## 10       1 series_10       9.62

``` r
average_viewership_1 <- viewers_tidy_df |>
  filter(series == 'series_1') |>  
  pull(viewership) |>                       
  mean(na.rm = TRUE)

average_viewership_5 <- viewers_tidy_df |>
  filter(series == 'series_5') |>  
  pull(viewership) |>                       
  mean(na.rm = TRUE)
```

``` r
cat("The average viewership in Season 1 is", average_viewership_1, "\n")
```

    ## The average viewership in Season 1 is 2.77

``` r
cat("The average viewership in Season 5 is", average_viewership_5, "\n")
```

    ## The average viewership in Season 5 is 10.0393
